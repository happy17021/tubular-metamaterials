{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f612c-4624-42b2-a364-12cca1ea4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, warnings, json, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7d32a-e3a4-4fb1-b075-120acdb87ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURVES_DIR = './curves'\n",
    "IMAGES_INDEX_XLSX = 'parsed_image_info.xlsx'  \n",
    "TRAIN_IMG_DIR = './train_images'\n",
    "TEST_IMG_DIR  = './test_images'\n",
    "SS_PATH = 'ss.pkl'\n",
    "BEST_PARAM_JSON = 'best_params_GeomRidgeSVD.json'\n",
    "BEST_MODEL_PATH = 'best_GeomRidgeSVD.pkl'\n",
    "\n",
    "SEED = 20\n",
    "np.random.seed(SEED)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "FORCE_TUNE  = False    \n",
    "ALPHAS_GRID = np.logspace(-6, 3, 19)  \n",
    "CV_FOLDS    = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655a498-0dd1-4b7c-ac54-45d53ba68c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_names_from_dir(d):\n",
    "    return set(f for f in os.listdir(d) if os.path.isfile(os.path.join(d, f)))\n",
    "\n",
    "def build_labels():\n",
    "    labels = pd.DataFrame(columns=['name'] + [f'y{i}' for i in range(200)])\n",
    "    for file in tqdm(os.listdir(CURVES_DIR), desc='Read curves'):\n",
    "        if not file.lower().endswith(('.xlsx','.xls','.csv')):\n",
    "            continue\n",
    "        tmp = pd.read_excel(os.path.join(CURVES_DIR, file), index_col=0).iloc[1:,].T\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp.columns = ['name'] + [f'y{i}' for i in range(200)]\n",
    "        labels = pd.concat([labels, tmp], axis=0, ignore_index=True)\n",
    "    labels2 = pd.read_excel(IMAGES_INDEX_XLSX)  # name + porosity + 9 params\n",
    "    return pd.merge(labels2, labels, on='name', how='inner')\n",
    "\n",
    "def get_split(labels):\n",
    "    train_csv = labels[labels['name'].isin(list_names_from_dir(TRAIN_IMG_DIR))].reset_index(drop=True)\n",
    "    test_csv  = labels[labels['name'].isin(list_names_from_dir(TEST_IMG_DIR))].reset_index(drop=True)\n",
    "    print(f\"Train samples: {len(train_csv)}, Test samples: {len(test_csv)}\")\n",
    "    return train_csv, test_csv\n",
    "\n",
    "def get_geom_X(df, use_auto=True, geom_param_cols=None):\n",
    "    if use_auto:\n",
    "        cols = [df.columns[1]] + df.columns[2:11].tolist()  # porosity + 9 params\n",
    "    else:\n",
    "        cols = ['porosity'] + geom_param_cols\n",
    "    return df[cols].to_numpy(np.float32), cols\n",
    "\n",
    "def eval_curves(y_true_is, y_pred_is, names, tag):\n",
    "    r2, area = [], []\n",
    "    for i in range(y_true_is.shape[0]):\n",
    "        r2.append(metrics.r2_score(y_true_is[i,:], y_pred_is[i,:]))\n",
    "        denom = np.trapz(y_true_is[i,:], dx=1.0)\n",
    "        nume = np.trapz(y_pred_is[i,:], dx=1.0)\n",
    "        area.append((nume/denom) if denom!=0 else np.nan)\n",
    "    eps=1e-8\n",
    "    denomM=np.maximum(np.abs(y_true_is), eps)\n",
    "    rel = np.sqrt(np.mean(((y_pred_is - y_true_is)/denomM)**2, axis=1))\n",
    "    return pd.DataFrame({\n",
    "        'name': names.reset_index(drop=True),\n",
    "        'Model': tag,\n",
    "        'R2': r2,\n",
    "        'AreaRatio': area,\n",
    "        'RelRMSE': rel\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6b874-c087-42c5-82ec-02955d461d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    labels = build_labels()\n",
    "    train_csv, test_csv = get_split(labels)\n",
    "    y_cols = [f'y{i}' for i in range(200)]\n",
    "\n",
    "\n",
    "    if os.path.exists(SS_PATH):\n",
    "        ss = joblib.load(SS_PATH)\n",
    "    else:\n",
    "        ss = StandardScaler().fit(labels[y_cols].to_numpy(np.float32))\n",
    "        joblib.dump(ss, SS_PATH)\n",
    "    y_train_std = ss.transform(train_csv[y_cols].to_numpy(np.float32))\n",
    "    y_test_std  = ss.transform(test_csv[y_cols].to_numpy(np.float32))\n",
    "    y_test_true_is = ss.inverse_transform(y_test_std)\n",
    "\n",
    "\n",
    "    USE_AUTO_GEOM_COLS = True\n",
    "    geom_param_cols = ['p1','p2','p3','p4','p5','p6','p7','p8','p9']\n",
    "    X_train, used_cols = get_geom_X(train_csv, USE_AUTO_GEOM_COLS, geom_param_cols)\n",
    "    X_test,  _         = get_geom_X(test_csv,  USE_AUTO_GEOM_COLS, geom_param_cols)\n",
    "    print(\"Geom features:\", used_cols)\n",
    "\n",
    "\n",
    "    do_tune = FORCE_TUNE or (not os.path.exists(BEST_PARAM_JSON))\n",
    "    if do_tune:\n",
    "        base = Ridge(solver='svd', random_state=SEED)\n",
    "        grid = GridSearchCV(\n",
    "            estimator=base,\n",
    "            param_grid={'alpha': ALPHAS_GRID},\n",
    "            cv=CV_FOLDS,\n",
    "            n_jobs=-1,  \n",
    "            verbose=1\n",
    "        )\n",
    "        with parallel_backend('threading'):  \n",
    "            grid.fit(X_train, y_train_std)\n",
    "        best_alpha = float(grid.best_params_['alpha'])\n",
    "        params = {'alphas_grid': list(map(float, ALPHAS_GRID)), 'chosen_alpha': best_alpha, 'solver': 'svd'}\n",
    "        json.dump(params, open(BEST_PARAM_JSON,'w'), indent=2)\n",
    "        print(\">>> Tuned alpha (SVD):\", best_alpha)\n",
    "    else:\n",
    "        params = json.load(open(BEST_PARAM_JSON,'r'))\n",
    "        best_alpha = float(params['chosen_alpha'])\n",
    "        print(\">>> Loaded cached alpha:\", best_alpha)\n",
    "\n",
    "    ridge = Ridge(alpha=best_alpha, solver='svd', random_state=SEED)\n",
    "    ridge.fit(X_train, y_train_std)\n",
    "    joblib.dump(ridge, BEST_MODEL_PATH)\n",
    "    print(\">>> Saved best model to\", BEST_MODEL_PATH)\n",
    "\n",
    "    y_pred_std = ridge.predict(X_test)\n",
    "    y_pred_is  = ss.inverse_transform(y_pred_std)\n",
    "    df = eval_curves(y_test_true_is, y_pred_is, test_csv['name'], 'Geom-Ridge-SVD-Tuned')\n",
    "    df.to_excel('metrics_GeomRidgeSVD_Tuned.xlsx', index=False)\n",
    "    pd.DataFrame(y_pred_is).assign(name=test_csv['name'].values).to_excel('pred_test_GeomRidgeSVD_Tuned.xlsx', index=False)\n",
    "    print(df[['R2','AreaRatio','RelRMSE']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689e1d9-3e69-4106-8a68-f32bccc2ee4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

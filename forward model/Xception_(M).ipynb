{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336c1fc-7ce8-4752-a07a-bb04ba847d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator   # ==== NEW ====\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "tensorflow.random.set_seed(20)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228962c0-2412-4615-a4d3-8de859682ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURVES_DIR = './curves'         \n",
    "IMAGES_INDEX_XLSX = 'images_index.xlsx'  \n",
    "IMAGES_ROOT = './images'         \n",
    "TRAIN_IMG_DIR = './train_images'   \n",
    "TEST_IMG_DIR  = './test_images'   \n",
    "\n",
    "labels = pd.DataFrame(columns=['name'] + ['y' + str(i) for i in range(200)])\n",
    "for file in tqdm(os.listdir(CURVES_DIR)):\n",
    "    if not file.lower().endswith(('.xlsx', '.xls', '.csv')):\n",
    "        continue\n",
    "    tmp = pd.read_excel(f'{CURVES_DIR}/{file}', index_col=0).iloc[1:,].T\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.columns = ['name'] + ['y' + str(i) for i in range(200)]\n",
    "    labels = pd.concat([labels, tmp], axis=0)\n",
    "\n",
    "labels2 = pd.read_excel(IMAGES_INDEX_XLSX)  \n",
    "labels = pd.merge(labels2, labels, how='inner', on='name')\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "y_cols = ['y' + str(i) for i in range(200)]\n",
    "labels[y_cols] = ss.fit_transform(labels[y_cols])\n",
    "joblib.dump(ss, 'ss.pkl')\n",
    "\n",
    "\n",
    "def list_names_from_dir(d):\n",
    "    files = [f for f in os.listdir(d) if os.path.isfile(os.path.join(d, f))]\n",
    "    return set(files)\n",
    "\n",
    "train_names = list_names_from_dir(TRAIN_IMG_DIR)\n",
    "test_names  = list_names_from_dir(TEST_IMG_DIR)\n",
    "\n",
    "\n",
    "train_csv = labels[labels['name'].isin(train_names)].reset_index(drop=True)\n",
    "test_csv  = labels[labels['name'].isin(test_names)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train samples: {len(train_csv)}, Test samples: {len(test_csv)}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4), dpi=120)\n",
    "for i in range(min(10, len(labels))):\n",
    "    y_values = labels.iloc[i, labels.columns.get_loc('y0'):labels.columns.get_loc('y199')+1].values\n",
    "    sns.lineplot(x=range(200), y=y_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bca5be3-ce85-482c-8d7e-80e4d370b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, csv_file, directory, batch_size, target_size, label_list,\n",
    "                 shuffle=True, augment=False):  # ==== CHANGED ====\n",
    "        self.csv_file = csv_file\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.label_list = label_list\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment                     \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        if self.augment:\n",
    "            \n",
    "            self.idg = ImageDataGenerator(\n",
    "                rotation_range=10,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=0.05,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "        else:\n",
    "            self.idg = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.csv_file) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.csv_file.iloc[k] for k in indexes]\n",
    "        X, y = self.__data_generation(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.csv_file))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch):\n",
    "        X1 = np.empty((self.batch_size, *self.target_size, 3), dtype=np.float32)\n",
    "        X2 = np.empty((self.batch_size, 1), dtype=np.float32)  # \n",
    "        y  = np.empty((self.batch_size, len(self.label_list) - 1), dtype=np.float32)\n",
    "\n",
    "        for i, data in enumerate(batch):\n",
    "            img_path = os.path.join(self.directory, data['name'])\n",
    "            image = load_img(img_path, target_size=self.target_size)\n",
    "            arr = img_to_array(image) / 255.0\n",
    "\n",
    "            if self.augment and self.idg is not None:\n",
    "                arr = self.idg.random_transform(arr)  \n",
    "\n",
    "            X1[i] = arr\n",
    "            X2[i, 0] = data[self.label_list[0]]   \n",
    "            y[i] = data[self.label_list[1:]]     \n",
    "\n",
    "        return [X1, X2], y\n",
    "\n",
    "\n",
    "label_list = ['porosity'] + y_cols\n",
    "batch_size = 16\n",
    "target_size = (256, 256)\n",
    "\n",
    "\n",
    "train_generator = CustomDataGenerator(train_csv, IMAGES_ROOT, batch_size, target_size, label_list,\n",
    "                                      shuffle=True, augment=True)     # ==== CHANGED ====\n",
    "test_generator  = CustomDataGenerator(test_csv,  IMAGES_ROOT, batch_size, target_size, label_list,\n",
    "                                      shuffle=False, augment=False)   # ==== CHANGED ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8db34-5205-46ac-8e60-80b8aee6adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_y(gen):\n",
    "    ys = []\n",
    "    for _i in range(len(gen)):\n",
    "        _, yy = gen[_i]\n",
    "        ys.append(yy)\n",
    "    return np.concatenate(ys, axis=0)\n",
    "\n",
    "y_train = stack_y(train_generator)\n",
    "y_test  = stack_y(test_generator)\n",
    "print(\"y_train.shape, y_test.shape =\", y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 3), dpi=120)\n",
    "    axs[0].plot(range(1, len(model_history.history['mse'])+1), model_history.history['mse'])\n",
    "    axs[0].plot(range(1, len(model_history.history['val_mse'])+1), model_history.history['val_mse'])\n",
    "    axs[0].set_title('Model MSE'); axs[0].set_ylabel('mse'); axs[0].set_xlabel('Epoch'); axs[0].legend(['train', 'val'], loc='best')\n",
    "    axs[1].plot(range(1, len(model_history.history['loss'])+1), model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss'])+1), model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss'); axs[1].set_ylabel('Loss'); axs[1].set_xlabel('Epoch'); axs[1].legend(['train', 'val'], loc='best')\n",
    "    fig.savefig('curve.jpg', dpi=600, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef42b6-3c3a-49e6-a6c8-30607bb7c59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input_image = Input(shape=(256, 256, 3))\n",
    "    input_features1 = Input(shape=(1,))  # porosity\n",
    "\n",
    "    base_model = tf.keras.applications.Xception(\n",
    "        weights='imagenet', include_top=False, input_shape=(256, 256, 3)\n",
    "    )\n",
    "    x = base_model(input_image)\n",
    "    x = Flatten()(x)\n",
    "    x = Concatenate()([x, input_features1])\n",
    "\n",
    "\n",
    "    for i in range(2):\n",
    "        x = Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=128, max_value=512, step=16),\n",
    "            activation=hp.Choice(f'activation_{i}', values=['relu', 'tanh'])\n",
    "        )(x)\n",
    "\n",
    "    output = Dense(200)(x)\n",
    "    model = Model(inputs=[input_image, input_features1], outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-3, sampling='LOG')\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mse']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,                \n",
    "    executions_per_trial=1,    \n",
    "    directory='my_dir',\n",
    "    project_name='helloworld'\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "tuner.search(train_generator, epochs=10, validation_data=test_generator, callbacks=[stop_early])\n",
    "\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "for i in range(2):\n",
    "    print(f\"Layer {i+1}: units={best_hps.get(f'units_{i}')}, act={best_hps.get(f'activation_{i}')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e707a0-a375-4571-a54b-25587719eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks=[tf.keras.callbacks.ModelCheckpoint(\"./best_model.h5\", save_best_only=True, monitor='val_loss'),\n",
    "               stop_early]\n",
    ")\n",
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36783f0-01b5-4dfb-9779-812dda44ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.insert(0, 'epoch', range(1, len(hist_df)+1)) \n",
    "\n",
    "hist_df.to_excel('history_epoch_metrics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9c872-6bd2-4ddb-a116-ab09198072e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model.h5', compile=False)\n",
    "\n",
    "y_test_pred  = model.predict(test_generator, verbose=0)\n",
    "y_train_pred = model.predict(train_generator, verbose=0)\n",
    "\n",
    "y_test_true    = ss.inverse_transform(y_test)\n",
    "y_test_pred_is = ss.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ee3b5-bd10-4059-b5a3-8092b53ef320",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_list, area_list = [], []\n",
    "for i in range(y_test_true.shape[0]):\n",
    "    r2_list.append(round(metrics.r2_score(y_test_true[i, :], y_test_pred_is[i, :]), 4))\n",
    "\n",
    "    denom = np.trapz(y_test_true[i, :], dx=1.0)\n",
    "    nume  = np.trapz(y_test_pred_is[i, :], dx=1.0)\n",
    "    area_list.append((nume / denom) if denom != 0 else np.nan)\n",
    "\n",
    "\n",
    "eps = 1e-8\n",
    "denom = np.maximum(np.abs(y_test_true), eps)              # shape: (N,200)\n",
    "rel_rmse_vec = np.sqrt(np.mean(((y_test_pred_is - y_test_true) / denom) ** 2, axis=1))\n",
    "rel_rmse_mean = float(np.nanmean(rel_rmse_vec))\n",
    "\n",
    "\n",
    "df_metrics = pd.DataFrame({\n",
    "    'name': test_csv['name'].reset_index(drop=True),\n",
    "    'R2': r2_list,\n",
    "    'AreaRatio': area_list,\n",
    "    'RelRMSE': rel_rmse_vec\n",
    "})\n",
    "df_metrics.to_excel('test_metrics_R2_Area_RelRMSE.xlsx', index=False)\n",
    "\n",
    "print(\"Test R² mean:\", np.nanmean(r2_list))\n",
    "print(\"Test AreaRatio mean:\", np.nanmean(area_list))\n",
    "print(\"Test RelRMSE mean:\", rel_rmse_mean)\n",
    "\n",
    "pd.DataFrame(y_test_true).assign(name=test_csv['name'].values).to_excel('Test-test.xlsx', index=False)\n",
    "pd.DataFrame(y_test_pred_is).assign(name=test_csv['name'].values).to_excel('Pred-test.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b85ea-b16e-46b8-aa42-cd7d74db048f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "k = min(10, y_test_true.shape[0])\n",
    "for i in range(k):\n",
    "    plt.figure(figsize=(8,3), dpi=120)\n",
    "    sns.lineplot(x=range(200), y=y_test_true[i,:], label='True')\n",
    "    sns.lineplot(x=range(200), y=y_test_pred_is[i,:], label='Pred')\n",
    "    plt.title(f\"{test_csv.iloc[i]['name']}  |  R²={r2_list[i]:.3f}, RelRMSE={rel_rmse_vec[i]:.3f}\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f3dc4-140f-4f16-862d-afd9037a8900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

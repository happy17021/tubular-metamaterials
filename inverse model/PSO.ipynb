{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b94cc-371f-483e-bdfe-c4a98e1863e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "n_particles = 20\n",
    "max_iter = 30\n",
    "error_threshold = 0.001\n",
    "w = 0.9\n",
    "c1 = 2.0\n",
    "c2 = 1.0\n",
    "\n",
    "\n",
    "param_bounds = [(4, 13)] * 4 + [(4, 13)] + [(4, 13)] * 2 + [(16, 112)] * 2\n",
    "\n",
    "param_names = ['top','left','bottom','right','diag1','diag2','vert','hori','x','y']\n",
    "\n",
    "model_A = load_model('best_model_A.h5')\n",
    "model_B = load_model('best_model_B.h5', compile=False)\n",
    "scaler_X = joblib.load('scaler_X.pkl')\n",
    "scaler_Y = joblib.load('scaler_Y.pkl')\n",
    "scaler_curve = joblib.load('ss.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c9cd7-4d6e-48fe-82ae-ddad242fee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_to_full_params(params_9d):\n",
    "    full = np.zeros(10, dtype=int)\n",
    "    full[0:4] = params_9d[0:4]\n",
    "    full[4] = full[5] = params_9d[4]  # diag2 = diag1\n",
    "    full[6:10] = params_9d[5:9]\n",
    "    return full\n",
    "\n",
    "def generate_image_from_params(params):\n",
    "    top, left, bottom, right, diag1, diag2, vert, hori, x, y = params.astype(int)\n",
    "    img = np.ones((128, 128), dtype=np.uint8) * 255\n",
    "    cv2.rectangle(img, (0, 0), (127, top - 1), 0, -1)\n",
    "    cv2.rectangle(img, (0, 0), (left - 1, 127), 0, -1)\n",
    "    cv2.rectangle(img, (0, 128 - bottom), (127, 127), 0, -1)\n",
    "    cv2.rectangle(img, (128 - right, 0), (127, 127), 0, -1)\n",
    "    cv2.line(img, (0, 0), (127, 127), 0, diag1)\n",
    "    cv2.line(img, (0, 127), (127, 0), 0, diag2)\n",
    "    cv2.line(img, (x, 0), (x, 127), 0, vert)\n",
    "    cv2.line(img, (0, y), (127, y), 0, hori)\n",
    "    top_half = np.hstack([img, np.fliplr(img)])\n",
    "    full_img = np.vstack([top_half, np.flipud(top_half)])\n",
    "    return full_img\n",
    "\n",
    "def calculate_porosity(img):\n",
    "    return np.sum(img == 255) / img.size\n",
    "\n",
    "def predict_curve_from_image(img_rgb, phi):\n",
    "    img_input = img_rgb[np.newaxis, ...] / 255.0\n",
    "    phi_input = np.array([[phi]], dtype=np.float32)\n",
    "    pred_std = model_A.predict([img_input, phi_input], verbose=0)[0].reshape(1, -1)\n",
    "    return scaler_curve.inverse_transform(pred_std)[0]\n",
    "\n",
    "def compute_error(true_curve, pred_curve):\n",
    "    return 1 - r2_score(true_curve, pred_curve)\n",
    "\n",
    "os.makedirs('final_generated_images', exist_ok=True)\n",
    "all_params, all_curves, all_errors = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf374147-d73a-4598-ad35-eb42519b5d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "total_start_time = time.time()\n",
    "time_records = []   \n",
    "\n",
    "\n",
    "df_all = pd.read_excel('target_curve.xlsx')\n",
    "x_vals = df_all.iloc[1:, 0].values\n",
    "curve_names = df_all.columns[1:]\n",
    "\n",
    "os.makedirs('comparison_curves', exist_ok=True)\n",
    "os.makedirs('error_curves', exist_ok=True)\n",
    "\n",
    "\n",
    "for idx, name in enumerate(curve_names):\n",
    "    curve_start_time = time.time()   \n",
    "    print(f\"\\nüîç optÔºö{name}\")\n",
    "    y_target = df_all[name].iloc[1:].values.astype(float)\n",
    "    norm_target = scaler_X.transform(y_target.reshape(1, -1)).reshape(1, 200, 1)\n",
    "\n",
    "    class Particle:\n",
    "        def __init__(self, init_pos=None):\n",
    "            self.position = np.array(init_pos, dtype=np.float64) if init_pos is not None else self.random_position()\n",
    "            self.velocity = np.random.uniform(-1, 1, size=9)\n",
    "            self.best_position = self.position.copy()\n",
    "            self.best_error = float('inf')\n",
    "            self.error = float('inf')\n",
    "        def random_position(self):\n",
    "            return np.array([np.random.randint(low, high+1) for low, high in param_bounds], dtype=np.float64)\n",
    "        def evaluate(self, target_curve):\n",
    "            full_param = expand_to_full_params(np.round(self.position).astype(int))\n",
    "            img = generate_image_from_params(full_param)\n",
    "            phi = calculate_porosity(img)\n",
    "            img_rgb = cv2.cvtColor(cv2.merge([img]*3), cv2.COLOR_BGR2RGB)\n",
    "            pred_curve = predict_curve_from_image(img_rgb, phi)\n",
    "            self.error = compute_error(target_curve, pred_curve)\n",
    "            if self.error < self.best_error:\n",
    "                self.best_position = self.position.copy()\n",
    "                self.best_error = self.error\n",
    "        def update_velocity(self, global_best):\n",
    "            r1, r2 = np.random.rand(2)\n",
    "            cognitive = c1 * r1 * (self.best_position - self.position)\n",
    "            social = c2 * r2 * (global_best - self.position)\n",
    "            self.velocity = w * self.velocity + cognitive + social\n",
    "        def update_position(self):\n",
    "            self.position += self.velocity\n",
    "            for i, (low, high) in enumerate(param_bounds):\n",
    "                self.position[i] = np.clip(int(round(self.position[i])), low, high)\n",
    "\n",
    "\n",
    "    pred_init = model_B.predict(norm_target)\n",
    "    params_init = scaler_Y.inverse_transform(pred_init)[0]\n",
    "    params_init = np.clip(np.round(params_init), 1, 128).astype(int)\n",
    "    params_init_short = np.delete(params_init, 5)\n",
    "\n",
    "    swarm = [Particle(init_pos=params_init_short)] + [Particle() for _ in range(n_particles - 1)]\n",
    "    global_best_position = None\n",
    "    global_best_error = float('inf')\n",
    "    error_log = []\n",
    "\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        for p in swarm:\n",
    "            p.evaluate(y_target)\n",
    "            if p.error < global_best_error:\n",
    "                global_best_error = p.error\n",
    "                global_best_position = p.position.copy()\n",
    "        error_log.append(global_best_error)\n",
    "        if global_best_error <= error_threshold:\n",
    "            break\n",
    "        for p in swarm:\n",
    "            p.update_velocity(global_best_position)\n",
    "            p.update_position()\n",
    "\n",
    "\n",
    "    best_param_full = expand_to_full_params(global_best_position)\n",
    "    img = generate_image_from_params(best_param_full)\n",
    "    img_rgb = cv2.cvtColor(cv2.merge([img]*3), cv2.COLOR_BGR2RGB)\n",
    "    phi = calculate_porosity(img)\n",
    "    img_name = name if name.endswith('.jpg') else name + '.jpg'\n",
    "    cv2.imwrite(f'final_generated_images/{img_name}', img_rgb)\n",
    "\n",
    "\n",
    "    pred_curve = predict_curve_from_image(img_rgb, phi)\n",
    "    all_curves.append(pd.Series(pred_curve, name=name))\n",
    "    all_params.append({'name': name, **{k: int(v) for k, v in zip(param_names, best_param_full)}})\n",
    "    all_errors.append(pd.Series(error_log, name=name))\n",
    "    \n",
    "\n",
    "    curve_end_time = time.time()\n",
    "    curve_elapsed = curve_end_time - curve_start_time\n",
    "    print(f\"‚è± curve {name} timeÔºö{curve_elapsed:.2f} sÔºàabout {curve_elapsed/60:.2f} minÔºâ\")\n",
    "\n",
    " \n",
    "    time_records.append({\n",
    "        \"name\": str(name),\n",
    "        \"seconds\": float(curve_elapsed),\n",
    "        \"minutes\": float(curve_elapsed/60.0),\n",
    "        \"iterations\": len(error_log) if 'error_log' in locals() else None,\n",
    "        \"best_error_(1-R2)\": float(global_best_error) if 'global_best_error' in locals() else None\n",
    "    })\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x_vals, y_target, label='Target')\n",
    "    plt.plot(x_vals, pred_curve, '--', label='Predicted')\n",
    "    plt.title(f'{name} Curve'); plt.legend(); plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'comparison_curves/compare_{name}.png')\n",
    "    if idx < 2:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(error_log, marker='o')\n",
    "    plt.title(f'{name} Error Convergence')\n",
    "    plt.xlabel('Iteration'); plt.ylabel('1 - R¬≤')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'error_curves/error_{name}.png')\n",
    "    if idx < 2:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "pd.DataFrame(all_params)[['name'] + param_names].to_excel('final_best_parameters.xlsx', index=False)\n",
    "\n",
    "\n",
    "df_all_curves = pd.concat(all_curves, axis=1)\n",
    "df_all_curves.insert(0, 'Displacement', x_vals)\n",
    "df_all_curves.to_excel('final_best_predicted_curves.xlsx', index=False)\n",
    "\n",
    "\n",
    "df_all_errors = pd.concat(all_errors, axis=1)\n",
    "df_all_errors.insert(0, 'Iteration', list(range(1, len(all_errors[0]) + 1)))\n",
    "df_all_errors.to_excel('error_per_iteration.xlsx', index=False)\n",
    "\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_elapsed = total_end_time - total_start_time\n",
    "print(\"okÔºÅ\")\n",
    "print(f\"timeÔºö{total_elapsed:.2f} sÔºàabout {total_elapsed/60:.2f} minÔºâ\")\n",
    "\n",
    "\n",
    "report_path = 'pso_time_report.xlsx'\n",
    "df_times = pd.DataFrame(time_records)\n",
    "\n",
    "\n",
    "total_row = {\n",
    "    \"name\": \"TOTAL\",\n",
    "    \"seconds\": total_elapsed,\n",
    "    \"minutes\": total_elapsed/60.0,\n",
    "    \"iterations\": None,\n",
    "    \"best_error_(1-R2)\": None\n",
    "}\n",
    "df_times_with_total = pd.concat([df_times, pd.DataFrame([total_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\n",
    "        \"num_curves\",\n",
    "        \"total_seconds\",\n",
    "        \"total_minutes\",\n",
    "        \"avg_seconds_per_curve\",\n",
    "        \"avg_minutes_per_curve\"\n",
    "    ],\n",
    "    \"value\": [\n",
    "        len(df_times),\n",
    "        total_elapsed,\n",
    "        total_elapsed/60.0,\n",
    "        (total_elapsed/len(df_times)) if len(df_times) > 0 else None,\n",
    "        (total_elapsed/60.0/len(df_times)) if len(df_times) > 0 else None\n",
    "    ]\n",
    "})\n",
    "\n",
    "with pd.ExcelWriter(report_path, engine='xlsxwriter') as writer:\n",
    "    df_times_with_total.to_excel(writer, index=False, sheet_name='PerCurve')\n",
    "    summary.to_excel(writer, index=False, sheet_name='Summary')\n",
    "\n",
    "print(f\"save{report_path}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8288484-02ac-448b-beeb-026ee8e4e2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f9526-15b2-4c80-9d32-2a985ecb8bce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e0551-92d7-46cb-9ca6-51fe776839b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643dd7a-0b97-4831-ac1b-e2c15ef818db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7dfe5-b22c-4096-aeed-654e293ed2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b1593-4faf-499f-9c19-19dfc1db03d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
